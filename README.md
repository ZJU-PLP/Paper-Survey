The classification of articles may be inaccurate due to personal limited knowledge level. 

# Content
*   [Data Structure](https://github.com/shinshiner/Paper-Survey#data-structure)
    *   [Tree](https://github.com/shinshiner/Paper-Survey#tree)
*   [Machine Learning](https://github.com/shinshiner/Paper-Survey#machine-learning)
    *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm)
*   [Neural Network](https://github.com/shinshiner/Paper-Survey#neural-network)
    *   [Framework](https://github.com/shinshiner/Paper-Survey#framework)
    *   [Network Architecture](https://github.com/shinshiner/Paper-Survey#network-architecture)
    *   [Neural Network Component](https://github.com/shinshiner/Paper-Survey#neural-network-component)
    *   [Optimizer](https://github.com/shinshiner/Paper-Survey#optimizer)
*   [Computer Vision](https://github.com/shinshiner/Paper-Survey#computer-vision)
    *   [Dataset](https://github.com/shinshiner/Paper-Survey#dataset)
    *   [2D Object Detection](https://github.com/shinshiner/Paper-Survey#2d-object-detection)
        *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-1)
    *   [3D Object Detection](https://github.com/shinshiner/Paper-Survey#3d-object-detection)
        *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-2)
    *   [2D Segmentation](https://github.com/shinshiner/Paper-Survey#2d-segmentation)
        *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-3)
    *   [3D Segmentation](https://github.com/shinshiner/Paper-Survey#3d-segmentation)
        *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-4)
    *   [2D Pose](https://github.com/shinshiner/Paper-Survey#2d-pose)
        *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-5)
    *   [3D Pose](https://github.com/shinshiner/Paper-Survey#3d-pose)
        *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-6)
    *   [Video](https://github.com/shinshiner/Paper-Survey#video)
        *   [Segmentation](https://github.com/shinshiner/Paper-Survey#segmentation)
        *   [Motion Representation](https://github.com/shinshiner/Paper-Survey#motion-representation)
*   [Generative Model](https://github.com/shinshiner/Paper-Survey#generative-model)
    *   [VAE (Variational Auto-Encoder)](https://github.com/shinshiner/Paper-Survey#vae-variational-auto-encoder)
        *   [Models](https://github.com/shinshiner/Paper-Survey#models)
        *   [Applications](https://github.com/shinshiner/Paper-Survey#applications)
    *   [GAN (Generative Adversarial Networks)](https://github.com/shinshiner/Paper-Survey#gan-generative-adversarial-networks)
    	*   [Models](https://github.com/shinshiner/Paper-Survey#models-1)
        *   [Applications](https://github.com/shinshiner/Paper-Survey#applications-1)
*   [Reinforcement Learning](https://github.com/shinshiner/Paper-Survey#reinforcement-learning)
    *   [Environment](https://github.com/shinshiner/Paper-Survey#environment)
    *   [Algorithm](https://github.com/shinshiner/Paper-Survey#algorithm-7)
    *	[RL in Games](https://github.com/shinshiner/Paper-Survey#rl-in-games)
    *   [Distributional RL](https://github.com/shinshiner/Paper-Survey#distributional-rl)
*   [Transfer Learning & Meta Learning](https://github.com/shinshiner/Paper-Survey#transfer-learning--meta-learning)
    *   [Algorithm or Model](https://github.com/shinshiner/Paper-Survey#algorithm-or-model)
    *   [Zero Shot Learning](https://github.com/shinshiner/Paper-Survey#zero-shot-learning)
*   [Robot](https://github.com/shinshiner/Paper-Survey#robot)
	*	[Dataset](https://github.com/shinshiner/Paper-Survey#dataset-1)
	*	[Hardware](https://github.com/shinshiner/Paper-Survey#hardware)
    *   [Grasping](https://github.com/shinshiner/Paper-Survey#grasping)
        *   [Grasping with RL](https://github.com/shinshiner/Paper-Survey#grasping-with-rl)
        *   [Grasping Unknown Objects](https://github.com/shinshiner/Paper-Survey#grasping-unknown-objects)
        *   [Grasping in Cluttered Environment](https://github.com/shinshiner/Paper-Survey#grasping-in-cluttered-environment)
        *   [Grasping via Segmentation](https://github.com/shinshiner/Paper-Survey#grasping-via-segmentation)
        *   [Grasping Points Selection](https://github.com/shinshiner/Paper-Survey#grasping-points-selection)
    *   [Active Perception](https://github.com/shinshiner/Paper-Survey#active-perception)
    *   [Machine Vision](https://github.com/shinshiner/Paper-Survey#machine-vision)
        *   [Motion Prediction](https://github.com/shinshiner/Paper-Survey#motion-prediction)
        *   [Vision via Interactive Manipulation](https://github.com/shinshiner/Paper-Survey#vision-via-interactive-manipulation)

# Data Structure

## Tree

* 【Kd-tree】[Multidimensional binary search trees used for associative searching](https://dl.acm.org/citation.cfm?id=361007) (1975)

* 【Oc-tree】[Octree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer](https://www.researchgate.net/publication/238720460_Octree_Encoding_A_New_Technique_for_the_Representation_Manipulation_and_Display_of_Arbitrary_3-D_Objects_by_Computer) (1980)

# Machine Learning

## Algorithm

* 【SVM】[Least squares support vector machine classifiers](https://lirias.kuleuven.be/bitstream/123456789/218716/2/Suykens_NeurProcLett.pdf) (**Springer** 1999)

* 【PCA】[Singular value decomposition and principal component analysis](https://link.springer.com/chapter/10.1007%2F0-306-47815-3_5) (**Springer** 2003)

# Neural Network

## Framework

* [Torch7: A MATLAB-like environment for machine learning](https://infoscience.epfl.ch//record/192376/files/Collobert_NIPSWORKSHOP_2011.pdf) (**NIPS workshop** 2011)

* [Caffe: Convolutional Architecture for Fast Feature Embedding](https://dl.acm.org/citation.cfm?id=2654889) (**arxiv** 2014)

* [TensorFlow: A System for Large-Scale Machine Learning](https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf) (**OSDI** 2016)

## Network Architecture

* [Long Short Term Memory Network](https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735) (**Journals** 1997)

* 【VGG16】[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) (**arxiv** 2014)

* [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/abs/1511.06581) (**arxiv** 2015)

* 【STN】[Recurrent Spatial Transformer Networks](https://arxiv.org/abs/1509.05329) (**arxiv** 2015)

* 【FCN】[Fully Convolutional Networks for Semantic Segmentation](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) (**cv-foundation** 2015)

* [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf) (**cv-foundation** 2015)

* 【C3D】[Learning Spatiotemporal Features with 3D Convolutional Networks](http://ieeexplore.ieee.org/abstract/document/7410867/) (**ICCV** 2015)

* 【ResNet】[Deep Residual Learning for Image Recognition](http://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) (**openaccess.thecvf** 2016)

* 【GCN】[Semi-supervised classification with graph convolutional networks](https://arxiv.org/pdf/1609.02907.pdf) (**ICLR** 2017)

* [Non-local Neural Networks](https://arxiv.org/abs/1711.07971) (**arxiv** 2017)

* 【SPN】[Learning Affinity via Spatial Propagation Networks](http://papers.nips.cc/paper/6750-learning-affinity-via-spatial-propagation-networks) (**NIPS** 2017)

* 【Capsule】[Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829) (**NIPS** 2017)

* [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861) (**arxiv** 2017)

* [PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning](https://arxiv.org/abs/1711.05769) (**arxiv** 2017)

* [PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes](https://arxiv.org/abs/1711.00199) (**arxiv** 2017)

* 【PSMNet】[Pyramid Stereo Matching Network](https://arxiv.org/abs/1803.08669) (**CVPR** 2018)

* [PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image](http://art-programmer.github.io/planenet/paper.pdf) (**CVPR** 2018)

* [SBNet: Sparse Blocks Network for Fast Inference](https://arxiv.org/abs/1801.02108) (**arxiv** 2018)

## Neural Network Component

* 【ReLu】[Rectified Linear Units Improve Restricted Boltzmann Machines](https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf) (**ICML** 2010)

* [Dropout: a simple way to prevent neural networks from overfitting](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer) (**jmlr** 2014)

* [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167) (**ICML** 2015)

* 【center loss】[A Discriminative Feature Learning Approach for Deep Face Recognition](https://link.springer.com/chapter/10.1007/978-3-319-46478-7_31) (**ECCV** 2016)

* [Group Normalization](https://arxiv.org/abs/1803.08494) (**arxiv** 2018)

## Optimizer

* 【ASGD】[Acceleration of stochastic approximation by averaging](https://dl.acm.org/citation.cfm?id=131098) (**Journals** 1992)

* 【Adagrad】[Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://jmlr.org/papers/v12/duchi11a.html) (**jmlr** 2011)

* [ADADELTA: An Adaptive Learning Rate Method](https://arxiv.org/abs/1212.5701) (**arxiv** 2012)

* 【RMSprop】[Generating Sequences With Recurrent Neural Networks](https://arxiv.org/abs/1308.0850) (**arxiv** 2013)

* [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980) (**ICLR** 2015)

* [Learning to learn by gradient descent by gradient descent](https://arxiv.org/abs/1606.04474) (**NIPS** 2016)

# Computer Vision

## Dataset

* [ImageNet: A large-scale hierarchical image database](http://ieeexplore.ieee.org/abstract/document/5206848/) (**CVPR** 2009)

* 【NYUV2】[Indoor segmentation and support inference from rgbd images](https://link.springer.com/chapter/10.1007%2F978-3-642-33715-4_54) (**ECCV** 2012)

* 【KITTI】[Vision meets robotics: The KITTI dataset](http://journals.sagepub.com/doi/full/10.1177/0278364913491297) (**IJRR** 2013)

* 【Daimler Urban Segmentation】[Efficient Multi-Cue Scene Segmentation](http://pdfs.semanticscholar.org/bb9b/45f4b97935a95272c409d212589bc2a9a0cc.pdf) (**GCPR** 2013)

* 【Pascal Context】[The Role of Context for Object Detection and Semantic Segmentation in the Wild](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Mottaghi_The_Role_of_2014_CVPR_paper.pdf) (**CVPR** 2014)

* 【Pascal VOC】[The Pascal Visual Object Classes Challenge: A Retrospective](https://link.springer.com/article/10.1007/s11263-014-0733-5) (**IJCV** 2014)

* 【COCO】[Microsoft COCO: Common Objects in Context](https://link.springer.com/chapter/10.1007/978-3-319-10602-1_48) (**ECCV** 2014)

* 【ILSVRC】[ImageNet Large Scale Visual Recognition Challenge](https://link.springer.com/article/10.1007/s11263-015-0816-y) (**IJCV** 2015)

* 【ModelNet40】[3D ShapeNets: A Deep Representation for Volumetric Shapes](https://pdfs.semanticscholar.org/3ed2/3386284a5639cb3e8baaecf496caa766e335.pdf) (**CVPR** 2015) Dataset is available at [\[website\]](http://modelnet.cs.princeton.edu/).

* 【Cityscapes】[The Cityscapes Dataset for Semantic Urban Scene Understanding](http://openaccess.thecvf.com/content_cvpr_2016/papers/Cordts_The_Cityscapes_Dataset_CVPR_2016_paper.pdf) (**CVPR** 2016)

* 【S3DIS】[3d semantic parsing of largescale indoor spaces](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Armeni_3D_Semantic_Parsing_CVPR_2016_paper.pdf) (**CVPR** 2016)

* 【ScanNet】[ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes](https://arxiv.org/pdf/1702.04405.pdf) (**CVPR workshop** 2018)

## 2D Object Detection

### Algorithm

* 【R-CNN】[Rich feature hierarchies for accurate object detection and semantic segmentation](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf?spm=5176.100239.blogcont55892.8.pm8zm1&file=Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf) (**CVPR** 2014)

* [Fast R-CNN](http://openaccess.thecvf.com/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf) (**ICCV** 2015)

* [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf) (**NIPS** 2015)

* [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) (**ECCV** 2016)

* [R-FCN: Object Detection via Region-based Fully Convolutional Networks](https://arxiv.org/abs/1605.06409) (**NIPS** 2016)

* 【YOLO】[You Only Look Once: Unified, Real-Time Object Detection](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf) (**CVPR** 2016)

* [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) (**openaccess.thecvf** 2017)

* [FSSD: Feature Fusion Single Shot Multibox Detector](https://arxiv.org/abs/1712.00960) (**arxiv** 2017)

* 【RFB-SSD】[Receptive Field Block Net for Accurate and Fast Object Detection](https://arxiv.org/abs/1711.07767) (**arxiv** 2017)

* 【RefineDet】[Single-Shot Refinement Neural Network for Object Detection](https://arxiv.org/abs/1711.06897) (**arxiv** 2017)

* [MegDet: A Large Mini-Batch Object Detector](https://arxiv.org/abs/1711.07240) (**arxiv** 2017)

* [Light-Head R-CNN: In Defense of Two-Stage Object Detector](https://arxiv.org/abs/1711.07264) (**arxiv** 2017)

* 【RetinaNet / Focal Loss】[Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) (**ICCV** 2017)

* [YOLOv3: An Incremental Improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf) (**??** 2018)

## 3D Object Detection

### Algorithm

* [SSD-6D: Making RGB-based 3D detection and 6D pose estimation great again](https://arxiv.org/abs/1711.10006) (**openaccess.thecvf** 2017)

## 2D Segmentation

### Algorithm

* 【U-Net】[U-net: Convolutional networks for biomedical image segmentation](http://www.cs.cmu.edu/~jeanoh/16-785/papers/ronnenberger-miccai2015-u-net.pdf) (**arxiv** 2015)

* 【DeepMask】[Learning to Segment Object Candidates](https://arxiv.org/pdf/1506.06204.pdf) (**arxiv** 2015)

* [Instance-aware Semantic Segmentation via Multi-task Network Cascades](https://arxiv.org/abs/1512.04412) (**CVPR** 2016)

* [Mask R-CNN](https://arxiv.org/abs/1703.06870) (**ICCV** 2017)

* 【W-Net】[W-Net: A Deep Model for Fully Unsupervised Image Segmentation](https://arxiv.org/pdf/1711.08506.pdf) (**arxiv** 2017)

* 【RefineNet】[RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_RefineNet_Multi-Path_Refinement_CVPR_2017_paper.pdf) (**CVPR** 2017)

* [Semantic Instance Segmentation with a Discriminative Loss Function](https://arxiv.org/abs/1708.02551) (**CVPR workshop** 2017)

* [Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081) (**CVPR** 2018)

* [Weakly Supervised Instance Segmentation using Class Peak Response](https://arxiv.org/pdf/1804.00880.pdf) (**CVPR** 2018)

* 【Mask^X RCNN】[Learning to Segment Every Thing](http://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Learning_to_Segment_CVPR_2018_paper.pdf) (**CVPR** 2018)

## 3D Segmentation

### Algorithm

* [Deep learning with sets and point clouds](https://arxiv.org/pdf/1611.04500.pdf) (**ICLR** 2017)

* [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf) (**CVPR** 2017)

* [3DContextNet: K-d Tree Guided Hierarchical Learning of Point Clouds Using Local and Global Contextual Cues](https://arxiv.org/pdf/1711.11379.pdf) (**CVPR** 2017)

* [PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://arxiv.org/abs/1706.02413) (**NIPS** 2017)

* [Escape from cells: Deep kd-networks for the recognition of 3d point cloud models](http://openaccess.thecvf.com/content_ICCV_2017/papers/Klokov_Escape_From_Cells_ICCV_2017_paper.pdf) (**ICCV** 2017)

* 【PointSIFT】[PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/1807.00652) (**arxiv** 2018)

* 【Kd-network】[PointCNN](https://arxiv.org/abs/1801.07791) (**arxiv** 2018)

* 【SO-Net】[SO-Net: Self-Organizing Network for Point Cloud Analysis](https://arxiv.org/pdf/1803.04249.pdf) (**CVPR** 2018)

* 【SGPN】[SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation](https://arxiv.org/pdf/1711.08588.pdf) (**CVPR** 2018)

* 【DGCNN】[Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/pdf/1801.07829.pdf)

## 2D Pose

### Algorithm

* 【open pose】[Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](http://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Realtime_Multi-Person_2D_CVPR_2017_paper.pdf) (**CVPR** 2017)

* 【G-RMI】[Towards accurate multi-person pose estimation in the wild](http://openaccess.thecvf.com/content_cvpr_2017/papers/Papandreou_Towards_Accurate_Multi-Person_CVPR_2017_paper.pdf) (**CVPR** 2017)

* [Joint Multi-Person Pose Estimation and Semantic Part Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Xia_Joint_Multi-Person_Pose_CVPR_2017_paper.pdf) (**CVPR** 2017)

* [RMPE: Regional Multi-Person Pose Estimation](http://openaccess.thecvf.com/content_ICCV_2017/papers/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.pdf) (**ICCV** 2017)

* [Vnect: Real-time 3d human pose estimation with a single rgb camera](https://dl.acm.org/citation.cfm?id=3073596) (**SIGGRAPH** 2017)

* 【CPN】[Cascaded Pyramid Network for Multi-Person Pose Estimation](https://arxiv.org/abs/1711.07319) (**CVPR** 2018)

## 3D Pose

### Algorithm

* [Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose](http://openaccess.thecvf.com/content_cvpr_2017/papers/Pavlakos_Coarse-To-Fine_Volumetric_Prediction_CVPR_2017_paper.pdf) (**CVPR** 2017)

## Video

### Segmentation

* [Learning to Segment Instances in Videos with Spatial Propagation Network](https://arxiv.org/abs/1709.04609) (**CVPR workshop 2017**)

* [SegFlow: Joint Learning for Video Object Segmentation and Optical Flow](http://openaccess.thecvf.com/content_ICCV_2017/papers/Cheng_SegFlow_Joint_Learning_ICCV_2017_paper.pdf) (**CVPR** 2017)

* [Learning Features by Watching Objects Move](http://openaccess.thecvf.com/content_cvpr_2017/papers/Pathak_Learning_Features_by_CVPR_2017_paper.pdf) (**CVPR** 2017)

### Motion Representation

* 【TVnet】[End-to-End Learning of Motion Representation for Video Understanding](https://arxiv.org/abs/1804.00413) (**CVPR** 2018)

# Generative Model

## VAE (Variational Auto-Encoder)

### Models

### Applications

* [Attribute2Image: Conditional Image Generation from Visual Attributes](https://link.springer.com/chapter/10.1007/978-3-319-46493-0_47) (**ECCV** 2016)

## GAN (Generative Adversarial Networks)

### Models

* 【GAN】[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (**NIPS** 2014)

* 【CGAN】[Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) (**arxiv** 2014)

* 【AAE】[Adversarial Autoencoders](https://arxiv.org/abs/1511.05644) (**arxiv** 2015)

* 【DCGAN】[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) (**arxiv** 2015)

### Applications

# Reinforcement Learning

## Environment

* [MuJoCo: A physics engine for model-based control](http://ieeexplore.ieee.org/abstract/document/6386109/?reload=true) (**International Conference on Intelligent Robots and Systems** 2012)

* [OpenAI Gym](https://arxiv.org/abs/1606.01540) (**arxiv** 2016)

* 【rllab】[Benchmarking Deep Reinforcement Learning for Continuous Control](https://arxiv.org/abs/1604.06778) (**jmlr** 2016)

* [DeepMind Lab](https://arxiv.org/abs/1612.03801) (**arxiv** 2016)

* [StarCraft II: A New Challenge for Reinforcement Learning](https://arxiv.org/abs/1708.04782) (**arxiv** 2017)

* [MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence](https://arxiv.org/abs/1712.00600) (**arxiv** 2017)

## Algorithm

* [Q-learning](https://link.springer.com/article/10.1007/BF00992698) (**Springer** 1992)

* 【DQN】[Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602) (**NIPS workshop** 2013)

* 【DPG】[Deterministic Policy Gradient Algorithms](https://hal.inria.fr/hal-00938992/) (**ICML** 2014)

* 【TRPO】[Trust Region Policy Optimization](http://proceedings.mlr.press/v37/schulman15.pdf) (**ICML** 2015)

* 【Double-DQN】[Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461) (**AAAI** 2016)

* 【h-DQN】[Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation](https://arxiv.org/abs/1604.06057) (**NIPS** 2016)

* 【A3C】[Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783) (**ICML** 2016)

* 【DDPG】[Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971) (**ICLR** 2016)

* 【NAF】[Continuous Deep Q-Learning with Model-based Acceleration](https://arxiv.org/abs/1603.00748) (**arxiv** 2016)

* 【ACER】[Sample Efficient Actor-Critic with Experience Replay](https://arxiv.org/abs/1611.01224) (**arxiv** 2016)

* 【GAIL】[Generative Adversarial Imitation Learning](https://arxiv.org/abs/1606.03476) (**NIPS** 2016)

* [Neural Episodic Control](https://arxiv.org/abs/1703.01988) (**arxiv** 2017)

* [Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT WITH AN OFF-POLICY CRITIC](https://arxiv.org/abs/1611.02247) (**ICLR** 2017)

* 【PPO】[Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347) (**arxiv** 2017)

* [Emergence of Locomotion Behaviours in Rich Environments](https://arxiv.org/abs/1707.02286) (**arxiv** 2017)

* 【ACKTR】[Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation](https://arxiv.org/abs/1708.05144) (**NIPS** 2017)

* 【HER】[Hindsight Experience Replay](https://arxiv.org/abs/1707.01495) (**NIPS** 2017)

* [Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295) (**ICLR** 2018)

## RL in Games

* [Control of Memory, Active Perception, and Action in Minecraft](https://arxiv.org/abs/1605.09128) (**arxiv** 2016)

## Distributional RL

* [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887) (**arxiv** 2017)

## Curiosity-Driven RL

* [Curiosity-driven Exploration by Self-supervised Prediction](https://arxiv.org/pdf/1705.05363.pdf) (**ICML** 2017)

* [Intrinsically motivated model learning for developing curious robots](http://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/AIJ15-Hester.pdf) (**Artificial Intelligence** 2017)

* [Computational Theories of Curiosity-Driven Learning](https://arxiv.org/pdf/1802.10546.pdf) (**arxiv** 2018)

* [Emergence of Structured Behaviors from Curiosity-Based Intrinsic Motivation](https://arxiv.org/pdf/1802.07461.pdf) (**arxiv** 2018)

# Transfer Learning & Meta Learning

## Algorithm or Model

* 【MAML】[Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400) (**arxiv** 2017)

* [OPTIMIZATION AS A MODEL FOR FEW-SHOT LEARNING](https://openreview.net/forum?id=rJY0-Kcll&noteId=ryq49XyLg) (**ICLR** 2017)

* 【SNAIL】[A Simple Neural Attentive Meta-Learner](https://openreview.net/forum?id=B1DmUzWAW&noteId=B1DmUzWAW) (**ICLR** 2018)

## Zero Shot Learning

* [ADAPT: Zero-Shot Adaptive Policy Transfer for Stochastic Dynamical Systems](https://web.stanford.edu/~yukez/papers/isrr2017.pdf) (**isrr** 2017)

* [Zero-Shot Object Detection](https://arxiv.org/abs/1804.04340) (**arxiv** 2018)

* [Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs](https://arxiv.org/pdf/1803.08035.pdf) (**CVPR** 2018)

# Robot

## Hardware

## Grasping

### Dataset

* [Deep Grasp: Detection and Localization of Grasps with Deep Neural Networks](https://arxiv.org/abs/1802.00520) (**arxiv** 2018)

* [Jacquard: A Large Scale Dataset for Robotic Grasp Detection](https://arxiv.org/abs/1803.11469) (**arxiv** 2018)

### Grasping with RL

### Grasping Unknown Objects

* [Ranking the good points: A comprehensive method for humanoid robots to grasp unknown objects](http://poeticonpp.csri-web.org:8989/PoeticonPlus/publications/1342_Gori_etal2013.pdf) (**International Conference on Advanced Robotics** 2013)

* [Model-Free Segmentation and Grasp Selection of Unknown Stacked Objects](http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ECCV_2014/papers/8693/86930659.pdf) (**ECCV** 2014)

* [Pick and Place Without Geometric Object Models](https://arxiv.org/pdf/1707.05615.pdf) (**ICRA** 2018)

### Grasping in Cluttered Environment

* [Real-Time 3D Segmentation of Cluttered Scenes for Robot Grasping](https://pub.uni-bielefeld.de/publication/2530701) (**ICHR** 2012)

* 【GPD】[High precision grasp pose detection in dense clutter](https://arxiv.org/pdf/1603.01564.pdf) (**IROS** 2016)

* [Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching](http://vision.princeton.edu/projects/2017/arc/paper.pdf) (**arxiv** 2017)

### Grasping via Segmentation

* [Grasping novel objects with depth segmentation](http://www.robotics.stanford.edu/~ang/papers/iros10-GraspingWithDepthSegmentation.pdf) (**IROS** 2010)

* [3D scene segmentation for autonomous robot grasping](https://www.researchgate.net/publication/261353757_3D_scene_segmentation_for_autonomous_robot_grasping) (**IROS** 2012)

### Grasping Points Selection

* [GP-GPIS-OPT: Grasp planning with shape uncertainty using Gaussian process implicit surfaces and Sequential Convex Programming](http://rll.berkeley.edu/~sachin/papers/Mahler-ICRA2015.pdf) (**ICRA** 2015)

* [Using Geometry to Detect Grasp Poses in 3D Point Clouds](http://www.ccs.neu.edu/home/atp/publications/grasp_poses_isrr2015.pdf) (**ISRR** 2015)

* [Dex-Net 1.0: A Cloud-Based Network of 3D Objects for Robust Grasp Planning Using a Multi-Armed Bandit Model with Correlated Rewards](http://goldberg.berkeley.edu/pubs/icra16-submitted-Dex-Net.pdf) (**ICRA** 2016)

* [Dex-Net 2.0: Deep Learning to Plan Robust Grasps with Synthetic Point Clouds and Analytic Grasp Metrics](https://arxiv.org/abs/1703.09312) (**arxiv** 2017)

* [Dex-Net 3.0: Computing Robust Robot Suction Grasp Targets in Point Clouds using a New Analytic Model and Deep Learning](https://arxiv.org/abs/1709.06670) (**arxiv** 2017)

## Active Perception

* [Learning Instance Segmentation by Interaction](http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w40/Pathak_Learning_Instance_Segmentation_CVPR_2018_paper.pdf) (**CVPR** 2018)

## Machine Vision

### Motion Prediction

* 【SE3-Net】[SE3-Nets: Learning Rigid Body Motion using Deep Neural Networks](https://arxiv.org/pdf/1606.02378.pdf) (**ICRA** 2017)

### Vision via Interactive Manipulation

* [Better Vision through Manipulation](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.9729&rep=rep1&type=pdf) (**Adaptive Behavior** 2003)

* [BIRTH OF THE OBJECT: DETECTION OF OBJECTNESS AND EXTRACTION OF OBJECT SHAPE THROUGH OBJECT–ACTION COMPLEXES](https://www.researchgate.net/profile/Danica_Kragic/publication/220065640_Birth_of_the_Object_Detection_of_Objectness_and_Extraction_of_Object_Shape_through_Object-Action_complexes/links/0deec52b935fedd8a8000000.pdf) (**International Journal of Humanoid Robotics** 2008)

* [Interactive Segmentation for Manipulation in Unstructured Environments](http://www.redaktion.tu-berlin.de/fileadmin/fg170/Publikationen_pdf/2009-icra.pdf) (**ICRA** 2009)

* [Generating Object Hypotheses in Natural Scenes through Human-Robot Interaction](http://www.diva-portal.org/smash/get/diva2:448466/FULLTEXT01.pdf) (**IROS** 2011)

* [Segmentation and learning of unknown objects through physical interaction](http://h2t.anthropomatik.kit.edu/pdf/Schiebener2011.pdf) (**IEEE/RAS Int. Conf. on Humanoid Robots (Humanoids)** 2011)


